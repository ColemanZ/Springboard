{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fe3348",
   "metadata": {},
   "source": [
    "# FEMA Disaster Predictor and Capstone\n",
    "*Year after year disasters strike the United States causing billions of dollars of damages and killing thousands of people. Individual states and counties are able to declare FEMA disasters under one of three different categories. Disaster Relief, Emergency Management and Fire Management are those categories. By declaring a disaster counties are able to receive Federal funds and bring in additional relief. This will be a predictor and visualization system to predict the amount of disasters in a given season in the United States.*\n",
    "## 1. Data\n",
    "Data was gathered from primarily one source. Since 1953 FEMA has provided data on every disaster declared.\n",
    "\n",
    "[FEMA Data](https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2)\n",
    "\n",
    "\n",
    "## 2. Method\n",
    "Create a weighted ensemble of highest performing models to create a predictive model for disasters per season.\n",
    "1. Gather FEMA data\n",
    "2. Clean data into a useable form\n",
    "3. Create features to be used in model building\n",
    "4. Build models \n",
    "5. Tune models\n",
    "6. Ensemble models in a weighted voting regressor model\n",
    "7. Determine highest performing model\n",
    "8. Visualize Data in a Tableau Dashboard\n",
    "\n",
    "## 3. Gather FEMA Data\n",
    "[Data Wrangling Notebook](https://github.com/ColemanZ/Springboard/blob/main/Disaster%20Capstone%20Data%20Wrangling.ipynb)\n",
    "Data was gathered from one source listed above. The FEMA data came in the form of a single CSV file containing a row for each d\n",
    "* **Problem 1** Too many states\n",
    "    At start there were 59 states provided. This ended up being US territories that are spread all across the world. This territories also have different thresholds for what is considered a disaster compared to states.\n",
    "* **Solution 1** Drop territories\n",
    "    After some deliberation I decided that this project would focus on the 50 US states and DC only.\n",
    "\n",
    "* **Problem 2** Bad Features\n",
    "    A number of features had issues. There were 3 features that contained null values. There were also a large number of useless columns that did not contain any useful or repeated information.\n",
    "* **Solution 2** Drop bad features\n",
    "    I decided that rather that columns that contained repeated information, unique identifiers, or null values should be dropped. \n",
    "    \n",
    "\n",
    "## 4. Clean Data Into a Useable Form\n",
    "[Exploratory Data Analysis Notebook](https://github.com/ColemanZ/Springboard/blob/main/Disaster%20Project%20EDA.ipynb)\n",
    "The data as presented needed very little cleaning at this point. After clearing up the amount of incident types we had I did some basic visualizations to get an understanding of the data.\n",
    "\n",
    "* **Problem 1** Too many incident types\n",
    "    Incident types define what kind of disaster took place. To begin there were nearly 35 incident types, many of which were very similar to other incident types. Since this is a classification determined by the state that is declaring a FEMA disaster there wasn't any similarity from one state to another for what is considered one incident type vs another. For instance the difference between a blizzard and winter storm might have only been the state that is declaring the disaster.\n",
    "* **Solution 1** Reconsolidate incident types\n",
    "    To limit the number of incident types and make the eventual visualizations more impactful I decided to group any similar incident types together. This brought the total incident types down to 21.\n",
    "    \n",
    "\n",
    "## 5. Create Features to be used in Model Building\n",
    "[Preprocessing and Training Data Development Notebook](https://github.com/ColemanZ/Springboard/blob/main/Disaster%20Capstone%20Pre-Processing.ipynb)\n",
    "\n",
    "A number of features were created for use in the eventual model building. We already touched on the \"incident length\". Since the eventual project was predicting number of disasters in a season we also needed to determine which month and which season a disaster took place. In addition to this a large number of features needed to be encoded to be usable in model building. Most difficult was building a loop that counted the number of disasters in a given season. A number of features also needed to be encoded to be useful in model building. One hot encoding worked with declaration type as there were only three unique values. Catboost encoding needed to be used for incident type and state. \n",
    "\n",
    "\n",
    "## 6. Build Models\n",
    "[Modeling Notebook](https://github.com/ColemanZ/Springboard/blob/main/Disaster%20Capstone%20Modeling.ipynb)\n",
    "After the data was cleaned and features were created I used pycaret to get a feel of what models needed to be built initially. After running that a number of times I chose to build 4 models to eventually get tuned and then analyse. \n",
    "**The Models Built**\n",
    "* Linear Regression\n",
    "* Random Forest Regression\n",
    "* Random Forest Classifier\n",
    "* XG Boost\n",
    "\n",
    "\n",
    "## 7. Tune Models\n",
    "After all the models were built they were all tuned. Some of them changed slightly others did not. \n",
    "**Random Forest Regression Model**\n",
    "**RMSE**:19.38\n",
    "**MSE**:375.51\n",
    "**Cross Validation Score**:.9947\n",
    "\n",
    "**Random Forest Classifier Model**\n",
    "**RMSE**:18.11\n",
    "**MSE**:328.13\n",
    "**Coefficiant of Determination**:.9832\n",
    "\n",
    "## 9. Evaluate Models and Conclusion\n",
    "Given how signficantly better the random forest models were there was no need to build a weighted voting classifier. Had this been built the success of the random forest regression model would have been dragged down but less successful models. The Random Forest Regressor model was \n",
    "## 10. Acknowledgements\n",
    "Thank you to Raghunandan Patthar, my mentor at Springboard for his excellent advice throughout this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4da7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
